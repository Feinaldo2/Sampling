#!/usr/bin/env python3
"""
ğŸ”¬ ç‰¹å¾å€¼åˆ†æå®éªŒ
åˆ†æconfidenceå’Œå„ç§attentionç‰¹å¾çš„æ•°å€¼åˆ†å¸ƒ
åŸºäºåˆ†å¸ƒç¡®å®šåˆç†çš„æƒé‡èŒƒå›´
"""

import subprocess
import time
import csv
import os
import json
import numpy as np
from datetime import datetime
import threading
import queue
import re

class FeatureAnalysisExperiment:
    def __init__(self, sample_size=20):
        self.sample_size = sample_size  # ç”¨è¾ƒå°‘æ ·æœ¬å¿«é€Ÿåˆ†æ
        self.results = []
        self.lock = threading.Lock()
        
        # åŠ¨æ€GPUåˆ†é…
        self.gpu_queue = queue.Queue()
        for i in range(8):
            self.gpu_queue.put(i)
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs("feature_analysis_results", exist_ok=True)
        
        # åˆå§‹åŒ–CSVæ–‡ä»¶
        self.csv_file = "feature_analysis_results/feature_stats.csv"
        with open(self.csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['attention_type', 'confidence_mean', 'confidence_std', 'attention_mean', 'attention_std', 'confidence_range', 'attention_range', 'suggested_weight_range'])
    
    def get_gpu(self):
        return self.gpu_queue.get()
    
    def release_gpu(self, gpu_id):
        self.gpu_queue.put(gpu_id)
    
    def get_analysis_configs(self):
        """è·å–åˆ†æé…ç½® - æ¯ç§attentionç±»å‹ç”¨é›¶æƒé‡æµ‹è¯•"""
        configs = []
        
        attention_types = [
            'pmass',
            'attention_entropy',
            'max_attention', 
            'self_attention',
            'attention_variance',
            'k_direction'
        ]
        
        # æ¯ç§attentionç±»å‹éƒ½ç”¨é›¶æƒé‡æµ‹è¯•ï¼Œè·å–åŸå§‹ç‰¹å¾å€¼åˆ†å¸ƒ
        for attention_type in attention_types:
            config_name = f"{attention_type}_analysis"
            weights = "1.00|0.00|0.00"  # é›¶æƒé‡ï¼Œåªè·å–ç‰¹å¾å€¼
            configs.append((config_name, attention_type, "linear", weights))
        
        return configs
    
    def run_single_analysis(self, config_name, attention_type, fusion_mode, weights):
        """è¿è¡Œå•ä¸ªåˆ†ææµ‹è¯•"""
        gpu_id = self.get_gpu()
        
        try:
            with self.lock:
                print(f"ğŸ” GPU{gpu_id} åˆ†æ: {config_name} ({attention_type}) - {self.sample_size}æ ·æœ¬")
            
            # åˆ›å»ºæµ‹è¯•è„šæœ¬
            script_content = f"""#!/bin/bash
export CUDA_VISIBLE_DEVICES={gpu_id}
cd /home/zhaoyifei/Sampling/slow-fast-sampling

# æ¿€æ´»condaç¯å¢ƒ
eval "$(conda shell.bash hook)"
conda activate slow_fast_sampling

# è®¾ç½®attentionç±»å‹ç¯å¢ƒå˜é‡
export ATTENTION_TYPE={attention_type}

python3 evaluation_script.py --model dream \\
  --model_args "pretrained=/home/zhaoyifei/Sampling/Models/Dream-base,max_new_tokens=256,diffusion_steps=256,temperature=0.2,top_p=0.95,alg=entropy,alg_temp=0.0,add_bos_token=true,is_feature_cache=False,is_cfg_cache=False,use_attention_fusion=True,fusion_type=static,static_weight={weights},fusion_mode={fusion_mode},k_exploration_steps=6,cycle_length_stability_window=2,use_fast_attention=True" \\
  --tasks gsm8k \\
  --num_fewshot 8 \\
  --batch_size 1 \\
  --limit {self.sample_size} \\
  --output_path ./feature_analysis_results/gpu{gpu_id}_{config_name} \\
  --log_samples
"""
            
            script_path = f"/tmp/feature_analysis_gpu{gpu_id}_{config_name}_{int(time.time())}.sh"
            with open(script_path, 'w') as f:
                f.write(script_content)
            os.chmod(script_path, 0o755)
            
            start_time = time.time()
            result = subprocess.run(['bash', script_path], capture_output=True, text=True, timeout=1200)
            end_time = time.time()
            duration = int(end_time - start_time)
            
            os.remove(script_path)
            
            if result.returncode == 0:
                # è§£æèåˆè°ƒè¯•ä¿¡æ¯ï¼Œæå–ç‰¹å¾å€¼
                feature_stats = self.extract_feature_stats(result.stdout, attention_type)
                
                if feature_stats:
                    with self.lock:
                        self.results.append({
                            'attention_type': attention_type,
                            'feature_stats': feature_stats,
                            'duration': duration
                        })
                        
                        print(f"âœ… GPU{gpu_id} å®Œæˆåˆ†æ: {config_name}")
                        print(f"   Confidence: å‡å€¼={feature_stats['confidence_mean']:.4f}, æ ‡å‡†å·®={feature_stats['confidence_std']:.4f}")
                        print(f"   Attention: å‡å€¼={feature_stats['attention_mean']:.4f}, æ ‡å‡†å·®={feature_stats['attention_std']:.4f}")
                    
                    return True
                else:
                    print(f"âš ï¸  GPU{gpu_id} ç‰¹å¾è§£æå¤±è´¥: {config_name}")
                    return False
            else:
                print(f"âŒ GPU{gpu_id} å¤±è´¥: {config_name}")
                return False
                
        except subprocess.TimeoutExpired:
            print(f"â° GPU{gpu_id} è¶…æ—¶: {config_name}")
            return False
        except Exception as e:
            print(f"ğŸ’¥ GPU{gpu_id} å¼‚å¸¸: {config_name} - {e}")
            return False
        finally:
            self.release_gpu(gpu_id)
    
    def extract_feature_stats(self, output, attention_type):
        """ä»è¾“å‡ºä¸­æå–ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯"""
        try:
            confidence_values = []
            attention_values = []

            # å…ˆæ‰“å°è¾“å‡ºç”¨äºè°ƒè¯•
            print(f"ğŸ” è°ƒè¯•è¾“å‡º ({attention_type}):")
            lines = output.split('\n')
            debug_lines = [line for line in lines if ('èåˆè°ƒè¯•' in line or 'conf=' in line or 'entropy=' in line or 'pmass=' in line)]
            for line in debug_lines[:5]:  # åªæ˜¾ç¤ºå‰5è¡Œ
                print(f"   {line}")

            # è§£æèåˆè°ƒè¯•ä¿¡æ¯
            for i, line in enumerate(lines):
                if 'ğŸ”¬ AdLLMèåˆè°ƒè¯•' in line and 'linear' in line:
                    # æŸ¥æ‰¾ä¸‹ä¸€è¡Œçš„ç‰¹å¾å€¼
                    if i + 1 < len(lines):
                        feature_line = lines[i + 1]
                        print(f"   ç‰¹å¾è¡Œ: {feature_line}")

                        # è§£æconfidenceå€¼
                        conf_match = re.search(r'conf=([0-9.]+)', feature_line)
                        if conf_match:
                            confidence_values.append(float(conf_match.group(1)))

                        # è§£æattentionç‰¹å¾å€¼ (æ ¹æ®attentionç±»å‹ç¡®å®šç‰¹å¾å)
                        if attention_type == 'pmass':
                            att_match = re.search(r'pmass=([0-9.]+)', feature_line)
                        elif attention_type == 'attention_entropy':
                            att_match = re.search(r'entropy=([0-9.]+)', feature_line)
                        else:
                            # å¯¹äºå…¶ä»–ç±»å‹ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸‰ä¸ªç‰¹å¾å€¼
                            parts = feature_line.split(',')
                            if len(parts) >= 3:
                                third_part = parts[2].strip()
                                att_match = re.search(r'=([0-9.]+)', third_part)
                            else:
                                att_match = None

                        if att_match:
                            attention_values.append(float(att_match.group(1)))
                            print(f"   æå–åˆ°attentionå€¼: {att_match.group(1)}")
                        else:
                            print(f"   æœªæ‰¾åˆ°attentionå€¼")
            
            if confidence_values and attention_values:
                confidence_mean = np.mean(confidence_values)
                confidence_std = np.std(confidence_values)
                attention_mean = np.mean(attention_values)
                attention_std = np.std(attention_values)
                
                confidence_range = f"[{min(confidence_values):.4f}, {max(confidence_values):.4f}]"
                attention_range = f"[{min(attention_values):.4f}, {max(attention_values):.4f}]"
                
                # åŸºäºç‰¹å¾å€¼åˆ†å¸ƒå»ºè®®æƒé‡èŒƒå›´
                # æƒé‡åº”è¯¥ä½¿å¾— attention_weight * attention_feature ä¸ confidence åœ¨åŒä¸€æ•°é‡çº§
                if attention_mean > 0:
                    # å»ºè®®æƒé‡èŒƒå›´ï¼šä½¿attentioné¡¹çš„è´¡çŒ®åœ¨confidenceçš„Â±50%èŒƒå›´å†…
                    max_weight = (confidence_mean * 0.5) / attention_mean
                    min_weight = -(confidence_mean * 0.5) / attention_mean
                    suggested_range = f"[{min_weight:.2f}, {max_weight:.2f}]"
                else:
                    suggested_range = "[-0.10, 0.10]"  # é»˜è®¤èŒƒå›´
                
                return {
                    'confidence_mean': confidence_mean,
                    'confidence_std': confidence_std,
                    'attention_mean': attention_mean,
                    'attention_std': attention_std,
                    'confidence_range': confidence_range,
                    'attention_range': attention_range,
                    'suggested_weight_range': suggested_range,
                    'confidence_values': confidence_values,
                    'attention_values': attention_values
                }
            
            return None
            
        except Exception as e:
            print(f"ç‰¹å¾è§£æå¼‚å¸¸: {e}")
            return None
    
    def run_feature_analysis(self):
        """è¿è¡Œç‰¹å¾åˆ†æå®éªŒ"""
        print("ğŸ”¬ ç‰¹å¾å€¼åˆ†æå®éªŒå¼€å§‹")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {self.sample_size} (å¿«é€Ÿåˆ†æ)")
        print(f"ğŸ¯ ç›®æ ‡: åˆ†æå„attentionç‰¹å¾çš„æ•°å€¼åˆ†å¸ƒï¼Œç¡®å®šåˆç†æƒé‡èŒƒå›´")
        print("=" * 80)
        
        configs = self.get_analysis_configs()
        
        print(f"ğŸ“Š åˆ†æé…ç½®æ•°é‡: {len(configs)}")
        print(f"â° é¢„è®¡æ—¶é—´: {len(configs) * 10 // 8} åˆ†é’Ÿ (8ä¸ªGPUå¹¶è¡Œ)")
        print("=" * 80)
        
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = []
            for config_name, attention_type, fusion_mode, weights in configs:
                future = executor.submit(self.run_single_analysis, config_name, attention_type, fusion_mode, weights)
                futures.append((future, config_name))
            
            completed = 0
            total = len(futures)
            
            for future in as_completed([f[0] for f in futures]):
                completed += 1
                # æ‰¾åˆ°å¯¹åº”çš„config_name
                config_name = None
                for f, name in futures:
                    if f == future:
                        config_name = name
                        break

                try:
                    future.result()
                    print(f"ğŸ“Š åˆ†æè¿›åº¦: {completed}/{total} - å®Œæˆ {config_name}")
                except Exception as e:
                    print(f"ğŸ’¥ {config_name} å¼‚å¸¸: {e}")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.generate_analysis_report()
    
    def generate_analysis_report(self):
        """ç”Ÿæˆç‰¹å¾åˆ†ææŠ¥å‘Š"""
        print("\n" + "=" * 100)
        print("ğŸ ç‰¹å¾å€¼åˆ†æå®éªŒå®Œæˆï¼")
        print("=" * 100)
        
        if not self.results:
            print("ğŸ˜” æ²¡æœ‰åˆ†æç»“æœ")
            return
        
        print(f"ğŸ“Š ç‰¹å¾å€¼åˆ†å¸ƒåˆ†æ:")
        print(f"{'Attentionç±»å‹':<18} {'Confidenceå‡å€¼':<12} {'Attentionå‡å€¼':<12} {'å»ºè®®æƒé‡èŒƒå›´':<20}")
        print("-" * 70)
        
        # å†™å…¥CSVå¹¶æ˜¾ç¤ºç»“æœ
        with open(self.csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            
            for result in self.results:
                att_type = result['attention_type']
                stats = result['feature_stats']
                
                print(f"{att_type:<18} {stats['confidence_mean']:<12.4f} {stats['attention_mean']:<12.4f} {stats['suggested_weight_range']:<20}")
                
                writer.writerow([
                    att_type,
                    stats['confidence_mean'],
                    stats['confidence_std'],
                    stats['attention_mean'],
                    stats['attention_std'],
                    stats['confidence_range'],
                    stats['attention_range'],
                    stats['suggested_weight_range']
                ])
        
        print(f"\nğŸ” è¯¦ç»†åˆ†æ:")
        for result in self.results:
            att_type = result['attention_type']
            stats = result['feature_stats']
            
            print(f"\n{att_type}:")
            print(f"   Confidence: å‡å€¼={stats['confidence_mean']:.4f}, æ ‡å‡†å·®={stats['confidence_std']:.4f}, èŒƒå›´={stats['confidence_range']}")
            print(f"   Attention:  å‡å€¼={stats['attention_mean']:.4f}, æ ‡å‡†å·®={stats['attention_std']:.4f}, èŒƒå›´={stats['attention_range']}")
            print(f"   å»ºè®®æƒé‡èŒƒå›´: {stats['suggested_weight_range']}")
        
        print(f"\nğŸ’¡ åŸºäºåˆ†æç»“æœçš„å»ºè®®:")
        print(f"   1. æƒé‡èŒƒå›´åº”è¯¥åŸºäºç‰¹å¾å€¼çš„å®é™…åˆ†å¸ƒ")
        print(f"   2. æƒé‡ Ã— attentionç‰¹å¾å€¼ åº”ä¸ confidence åœ¨åŒä¸€æ•°é‡çº§")
        print(f"   3. å»ºè®®çš„æƒé‡èŒƒå›´å·²ä¿å­˜åˆ° {self.csv_file}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ç‰¹å¾å€¼åˆ†æå®éªŒ')
    parser.add_argument('--samples', type=int, default=20, help='åˆ†ææ ·æœ¬æ•°é‡')
    
    args = parser.parse_args()
    
    experiment = FeatureAnalysisExperiment(sample_size=args.samples)
    experiment.run_feature_analysis()
